{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Scene Recognition with Bag-of-Words\n",
    "For this project, you will need to report performance for two\n",
    "combinations of features / classifiers. It is suggested you code them in\n",
    "this order, as well:\n",
    "1. Nearest neighbor classifier\n",
    "2. Bag of sift features and nearest neighbor classifier\n",
    "\n",
    "The starter code is initialized to 'placeholder' just so that the starter\n",
    "code does not crash when run unmodified and you can get a preview of how\n",
    "results are presented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Set up parameters, image paths and category list\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import cv2\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import pickle\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from proj3_code.utils import *\n",
    "import proj3_code.student_code as sc\n",
    "\n",
    "# Importing tests\n",
    "from proj3_unit_tests.test_student_code import (test_build_vocabulary_shape,\n",
    "    test_build_vocabulary_values, test_get_bags_of_sifts,\n",
    "    test_kmeans_quantize_exact_matches, test_kmeans_quantize_noisy_continuous, \n",
    "    test_kmeans_2_classes_1d_features, test_kmeans_5_classes_2d_features,\n",
    "    test_nearest_neighbor_classify,\n",
    "    test_nearest_neighbor_classify_k, verify, test_pairwise_distances)\n",
    "\n",
    "# This is the list of categories / directories to use. The categories are\n",
    "# somewhat sorted by similarity so that the confusion matrix looks more\n",
    "# structured (indoor and then urban and then rural).\n",
    "categories = ['Kitchen', 'Store', 'Bedroom', 'LivingRoom', 'Office', 'Industrial', 'Suburb',\n",
    "              'InsideCity', 'TallBuilding', 'Street', 'Highway', 'OpenCountry', 'Coast',\n",
    "              'Mountain', 'Forest'];\n",
    "# This list of shortened category names is used later for visualization\n",
    "abbr_categories = ['Kit', 'Sto', 'Bed', 'Liv', 'Off', 'Ind', 'Sub',\n",
    "                   'Cty', 'Bld', 'St', 'HW', 'OC', 'Cst',\n",
    "                   'Mnt', 'For'];\n",
    "\n",
    "# Number of training examples per category to use. Max is 100. For\n",
    "# simplicity, we assume this is the number of test cases per category, as\n",
    "# well.\n",
    "num_train_per_cat = 100\n",
    "\n",
    "# This function returns lists containing the file path for each train\n",
    "# and test image, as well as lists with the label of each train and\n",
    "# test image. By default all four of these lists will have 1500 elements\n",
    "# where each element is a string.\n",
    "data_path = osp.join('..', 'data')\n",
    "# train_image_paths, test_image_paths, train_labels, test_labels = get_image_paths(data_path,\n",
    "#                                                                                  categories,\n",
    "#                                                                                  num_train_per_cat);\n",
    "train_image_arrays, test_image_arrays, train_labels, test_labels = get_image_arrays(data_path,\n",
    "                                                                                 categories,\n",
    "                                                                               num_train_per_cat)\n",
    "if len(train_image_arrays) == 0:\n",
    "    print(data_path, 'not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Tiny Image features with Nearest Neighbor classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1a: Pairwise distances\n",
    "\n",
    "In order to perform nearest neighbor classification, we'll need a distance metric. In `pairwise_distances()` you'll be implementing a Euclidean distance method. Recall that in 2D, the Euclidean distance between two vectors $X = [x_1, x_2]$ and $Y = [y_1, y_2]$ is defined as\n",
    "\n",
    "$$dist(X, Y) = \\sqrt{(y_1 - x_1)^2 + (y_2 - x_2)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_pairwise_distances():\u001b[31m\"Wrong\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(\"test_pairwise_distances():\" + verify(test_pairwise_distances))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1a: Represent each image with the Tiny Image feature\n",
    "\n",
    "Each function to construct features should return an N x d numpy array, where N is the number of paths passed to the function and d is the dimensionality of each image representation. See the code in utils.py for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the TINY IMAGE representation for images\n",
      "(1500, 256) (1500, 256)\n"
     ]
    }
   ],
   "source": [
    "print('Using the TINY IMAGE representation for images')\n",
    "\n",
    "size = 16\n",
    "train_image_feats = get_tiny_images(train_image_arrays, size)\n",
    "test_image_feats = get_tiny_images(test_image_arrays, size)\n",
    "\n",
    "print(train_image_feats.shape, test_image_feats.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1b: Classify each test image by training and using the Nearest Neighbor classifier\n",
    "\n",
    "To run the following cells you will need to implement the nearest neighbor classifier. See the function stub for details.\n",
    "\n",
    "Each function to classify test features will return an N element list, where N is the number of test cases and each entry is a string indicating the predicted category for each test image. Each entry in 'predicted_categories' must be one of the 15 strings in 'categories'. See the starter code for each function for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nearest_neighbor_classify()\u001b[32m\"Correct\"\u001b[0m\n",
      "test_nearest_neighbor_classify_k()\u001b[32m\"Correct\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Test cases for nearest neighbor classify\n",
    "print(\"test_nearest_neighbor_classify()\" + verify(test_nearest_neighbor_classify))\n",
    "print(\"test_nearest_neighbor_classify_k()\" + verify(test_nearest_neighbor_classify_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments\n",
    "Vary `size` and `k` to run your experiments\n",
    "\n",
    "If we wanted to evaluate our recognition method properly we would train\n",
    "and test on many random splits of the data. You are not required to do so\n",
    "for this project.\n",
    "\n",
    "`show_results()` function will create a confusion matrix each time it is called. It will save the confusion matrix figure in the location specified.\n",
    "\n",
    "View the confusion matrix to help interpret your classifier performance. Where is it making mistakes? Are the confusions reasonable?\n",
    "\n",
    "Interpreting your performance with 100 training examples per category:\n",
    "- accuracy  =   0 -> Your code is broken (probably not the classifier's fault! A classifier would have to be amazing to perform this badly).\n",
    "- accuracy ~= .07 -> Your performance is chance. Something is broken or you ran the starter code unchanged.\n",
    "- accuracy ~= .15 ~ .20 -> Rough performance with tiny images and nearest neighbor classifier. Performance goes up a few percentage points with K-NN instead of 1-NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NEAREST NEIGHBOR classifier to predict test set categories\n"
     ]
    }
   ],
   "source": [
    "size = 16\n",
    "k = 15\n",
    "\n",
    "train_image_feats = get_tiny_images(train_image_arrays, size)\n",
    "test_image_feats = get_tiny_images(test_image_arrays, size)\n",
    "\n",
    "\n",
    "print('Using NEAREST NEIGHBOR classifier to predict test set categories')\n",
    "predicted_labels = sc.nearest_neighbor_classify(train_image_feats, train_labels, test_image_feats, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "pycmVectorError",
     "evalue": "Input vectors must have same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mpycmVectorError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m show_results(test_labels, categories, abbr_categories,predicted_labels, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcm.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/computer-vision/hw/ps3/proj3_code/utils.py:204\u001b[0m, in \u001b[0;36mshow_results\u001b[0;34m(test_labels, categories, abbr_categories, predicted_categories, savefile)\u001b[0m\n\u001b[1;32m    202\u001b[0m y_true \u001b[38;5;241m=\u001b[39m [cat2idx[cat] \u001b[38;5;28;01mfor\u001b[39;00m cat \u001b[38;5;129;01min\u001b[39;00m test_labels]\n\u001b[1;32m    203\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m [cat2idx[cat] \u001b[38;5;28;01mfor\u001b[39;00m cat \u001b[38;5;129;01min\u001b[39;00m predicted_categories]\n\u001b[0;32m--> 204\u001b[0m cm \u001b[38;5;241m=\u001b[39m ConfusionMatrix(y_true, y_pred)\n\u001b[1;32m    205\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[1;32m    206\u001b[0m plt_cm \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/proj3/lib/python3.11/site-packages/pycm/pycm_obj.py:97\u001b[0m, in \u001b[0;36mConfusionMatrix.__init__\u001b[0;34m(self, actual_vector, predict_vector, matrix, digit, threshold, file, sample_weight, transpose, classes, is_imbalanced, metrics_off)\u001b[0m\n\u001b[1;32m     94\u001b[0m     matrix_param \u001b[38;5;241m=\u001b[39m __obj_array_handler__(\n\u001b[1;32m     95\u001b[0m         matrix, classes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     matrix_param \u001b[38;5;241m=\u001b[39m __obj_vector_handler__(\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28mself\u001b[39m, actual_vector, predict_vector, threshold, sample_weight, classes)\n\u001b[1;32m     99\u001b[0m __obj_assign_handler__(\u001b[38;5;28mself\u001b[39m, matrix_param)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m metrics_off:\n",
      "File \u001b[0;32m~/miniconda3/envs/proj3/lib/python3.11/site-packages/pycm/pycm_handler.py:228\u001b[0m, in \u001b[0;36m__obj_vector_handler__\u001b[0;34m(cm, actual_vector, predict_vector, threshold, sample_weight, classes)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m pycmVectorError(VECTOR_TYPE_ERROR)\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(actual_vector) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(predict_vector):\n\u001b[0;32m--> 228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m pycmVectorError(VECTOR_SIZE_ERROR)\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(actual_vector) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(predict_vector) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m pycmVectorError(VECTOR_EMPTY_ERROR)\n",
      "\u001b[0;31mpycmVectorError\u001b[0m: Input vectors must have same length"
     ]
    }
   ],
   "source": [
    "show_results(test_labels, categories, abbr_categories,predicted_labels, 'cm.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Bag of SIFT features with Nearest Neighbor classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2a: Represent each image with the Bag of SIFT feature\n",
    "\n",
    "Now we will implement a more advanced feature set to describe our images - SIFT features! To build the SIFT vocabulary for bag of words, you will need to implement the k-means clustering algorithm and utilize it in your build vocabulary function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, we have provided you with a simple visual demo on how kmeans works. No need to write any code yet, run the next cell, and play around with the slider to check the kmeans clustering process. (Credits to teaching staff from CS6601; thank you Prof. Starner!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<numpy.lib.npyio.NpzFile object at 0x000001ABC3B38748>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a953e40f6db54822b8166361c5336769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='i', max=10, min=1), Output()), _dom_classes=('widget-int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import *\n",
    "import matplotlib.pyplot as plt\n",
    "K = 3\n",
    "data = np.load('../proj3_unit_tests/test_data/kmeans.npz', allow_pickle=True)\n",
    "print(data)\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "means_history = data['means']\n",
    "clusters_history = data['clu']\n",
    "\n",
    "# This is an interactive cell to see the progress of training your K-means algorithm.\n",
    "# Feel free to improve the visualization code and share it with your classmates on Piazza\n",
    "def get_cluster(i):\n",
    "    clusters = clusters_history[i] # Get the clusters from K-means' i-th iteration\n",
    "    plt.figure(None, figsize=(15,6)) # Set the plot size\n",
    "    plt.suptitle('Drag the slider to see the algorthm training progress')\n",
    "    ax1=plt.subplot(1, 2, 1)\n",
    "    ax1.set_title('K-means clsuters - step %d' % i)\n",
    "    for k in range(K):\n",
    "        plt.plot(X[clusters==k,0], X[clusters==k,1], '.')\n",
    "    # Just to get a flavour of how the data looks like\n",
    "    ax2=plt.subplot(1, 2, 2)\n",
    "    ax2.set_title('Ground truth clusters')\n",
    "    for i in np.unique(y):\n",
    "        ax2.plot(X[y==i,0],X[y==i,1],'.')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "interactive(get_cluster, i=(1,len(clusters_history)-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "test_kmeans_2_classes_1d_features()\u001b[32m\"Correct\"\u001b[0m\n",
      "0\n",
      "test_kmeans_5_classes_2d_features()\u001b[32m\"Correct\"\u001b[0m\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "test_kmeans_2_classes_1d_features()\u001b[32m\"Correct\"\u001b[0m\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "test_kmeans_5_classes_2d_features()\u001b[32m\"Correct\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(\"test_kmeans_2_classes_1d_features()\" + verify(test_kmeans_2_classes_1d_features))\n",
    "print(\"test_kmeans_5_classes_2d_features()\" + verify(test_kmeans_5_classes_2d_features))\n",
    "\n",
    "print(\"test_kmeans_2_classes_1d_features()\" + verify(test_build_vocabulary_shape))\n",
    "print(\"test_kmeans_5_classes_2d_features()\" + verify(test_build_vocabulary_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a new vocabulary, make sure `vocab_filename` is different than the old vocabulary, or delete the old one.\n",
    "\n",
    "**Important: note the logic for this cell: if the vocab file is present in the directory, then we'll proceed directly to getting SIFT representations; otherwise the vocab is built from scratch. The first time you run the cell, expect running time to be at least 10 minutes, as we are building the vocab as well as getting SIFT representations at the same time. Hence, make sure that you have passed all unit tests for this section before proceeding with the following cell!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the BAG-OF-SIFT representation for images\n",
      "No existing visual word vocabulary found. Computing one from training images\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "../data/vocab.pkl saved\n"
     ]
    }
   ],
   "source": [
    "print('Using the BAG-OF-SIFT representation for images')\n",
    "\n",
    "vocab_size = 50  # Larger values will work better (to a point) but be much slower to compute\n",
    "stride = 20\n",
    "max_iter = 10\n",
    "vocab_filename = \"../data/vocab.pkl\"\n",
    "\n",
    "if not osp.isfile(vocab_filename):\n",
    "    # Construct the vocabulary\n",
    "    print('No existing visual word vocabulary found. Computing one from training images')\n",
    "    vocab = sc.build_vocabulary(train_image_arrays, vocab_size, stride, max_iter)\n",
    "    with open(vocab_filename, 'wb') as f:\n",
    "        pickle.dump(vocab, f)\n",
    "        print('{:s} saved'.format(vocab_filename))\n",
    "else:\n",
    "    with open(vocab_filename, 'rb') as f:\n",
    "        vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have built our vocabulary of visual words, we will use it to process our training and testing images.\n",
    "\n",
    "You will need to implement two analagous functions to run the cell below\n",
    "\n",
    "**Note: running on the full dataset will take some time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_kmeans_quantize_exact_matches()\u001b[32m\"Correct\"\u001b[0m\n",
      "test_kmeans_quantize_noisy_continuous()\u001b[32m\"Correct\"\u001b[0m\n",
      "test_get_bags_of_sifts()\u001b[32m\"Correct\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(\"test_kmeans_quantize_exact_matches()\" + verify(test_kmeans_quantize_exact_matches))\n",
    "print(\"test_kmeans_quantize_noisy_continuous()\" + verify(test_kmeans_quantize_noisy_continuous))\n",
    "\n",
    "print(\"test_get_bags_of_sifts()\" + verify(test_get_bags_of_sifts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This may take a long time to run depending on stride. \n",
    "# You may want to save the features for faster experimentation.\n",
    "\n",
    "bags_of_sift_stride = 5\n",
    "train_image_feats = sc.get_bags_of_sifts(train_image_arrays, vocab, bags_of_sift_stride)\n",
    "test_image_feats = sc.get_bags_of_sifts(test_image_arrays, vocab, bags_of_sift_stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2b: Classify each test image by training and using the Nearest Neighbor classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print('Using NEAREST NEIGHBOR classifier to predict test set categories')\n",
    "predicted_categories = sc.nearest_neighbor_classify(train_image_feats, train_labels, test_image_feats, k = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2c: Build a confusion matrix and score the recognition system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_results(test_labels, categories, abbr_categories, predicted_categories, 'cm.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We have seen that a basic classifier as simple as kNN is sufficient to get this classification task done with around 50% accuracy; you may choose to experiment with SVM classifier, which can boost your performance up to 60%, but that's not required for this project.\n",
    "\n",
    "This shows you how things are done in the pre-deep learning era, and the result is, uh, okay. These days with neural networks, 80% ~ 90% accuracies can be achieved with ease."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
